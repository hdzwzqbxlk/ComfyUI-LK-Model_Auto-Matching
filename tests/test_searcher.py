"""
ç½‘ç»œæœç´¢æ¨¡å—æµ‹è¯•è„šæœ¬
ç”¨äºéªŒè¯ utils.py ä¸­çš„æœç´¢è¯æå–å’Œç›¸ä¼¼åº¦è®¡ç®—åŠŸèƒ½ (åŸ searcher.py åŠŸèƒ½)
"""
import sys
import os
import asyncio

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils import AdvancedTokenizer, NOISE_SUFFIXES
from searcher import ModelSearcher

def test_extract_search_terms():
    """æµ‹è¯•æœç´¢è¯æå–åŠŸèƒ½"""
    
    test_cases = [
        # (è¾“å…¥æ–‡ä»¶å, é¢„æœŸåŒ…å«çš„å…³é”®è¯)
        ("realvisxl_v3.0_turbo_fp16.safetensors", ["realvisxl"]),
        ("sd_xl_base_1.0.safetensors", ["sd", "xl"]),
        ("v1-5-pruned-emaonly.ckpt", ["v1"]),
        ("flux1-dev.safetensors", ["flux1", "dev"]),
        ("SDXL_Juggernaut_XL_v9.safetensors", ["juggernaut", "xl"]),
        ("controlnet-canny-sdxl-1.0.safetensors", ["controlnet", "canny", "sdxl"]),
    ]
    
    print("=" * 60)
    print("æµ‹è¯•: AdvancedTokenizer.extract_search_terms")
    print("=" * 60)
    
    passed = 0
    failed = 0
    
    for filename, expected_keywords in test_cases:
        terms = AdvancedTokenizer.extract_search_terms(filename)
        # æ£€æŸ¥è‡³å°‘æœ‰ä¸€ä¸ªæœç´¢è¯åŒ…å«é¢„æœŸå…³é”®è¯
        all_terms_text = ' '.join(terms).lower()
        
        missing = [kw for kw in expected_keywords if kw.lower() not in all_terms_text]
        
        if not missing:
            print(f"âœ“ {filename}")
            print(f"  -> æå–è¯: {terms}")
            passed += 1
        else:
            print(f"âœ— {filename}")
            print(f"  -> æå–è¯: {terms}")
            print(f"  -> ç¼ºå¤±å…³é”®è¯: {missing}")
            failed += 1
    
    print(f"\nç»“æœ: {passed} é€šè¿‡, {failed} å¤±è´¥")
    return failed == 0


def test_calculate_similarity():
    """æµ‹è¯•ç›¸ä¼¼åº¦è®¡ç®—åŠŸèƒ½"""
    
    test_cases = [
        # (åç§°A, åç§°B, é¢„æœŸç›¸ä¼¼åº¦èŒƒå›´)
        ("realvisxl_v3", "realvisxl-v3.0-turbo", (0.4, 1.0)),  # åº”è¯¥é«˜
        ("sd_xl_base", "stable-diffusion-xl-base-1.0", (0.25, 1.0)),  # ä¸­ç­‰
        ("flux1-dev", "flux.1-dev", (0.5, 1.0)),  # åº”è¯¥é«˜
        ("my_random_model", "completely_different_thing", (0.0, 0.3)),  # åº”è¯¥ä½
        ("controlnet-canny", "controlnet_canny_sdxl", (0.4, 1.0)),  # åº”è¯¥é«˜
    ]
    
    print("\n" + "=" * 60)
    print("æµ‹è¯•: AdvancedTokenizer.calculate_similarity")
    print("=" * 60)
    
    passed = 0
    failed = 0
    
    for name_a, name_b, (min_score, max_score) in test_cases:
        score = AdvancedTokenizer.calculate_similarity(name_a, name_b)
        
        if min_score <= score <= max_score:
            print(f"âœ“ '{name_a}' vs '{name_b}'")
            print(f"  -> ç›¸ä¼¼åº¦: {score:.3f} (é¢„æœŸèŒƒå›´: {min_score}-{max_score})")
            passed += 1
        else:
            print(f"âœ— '{name_a}' vs '{name_b}'")
            print(f"  -> ç›¸ä¼¼åº¦: {score:.3f} (é¢„æœŸèŒƒå›´: {min_score}-{max_score}) - è¶…å‡ºèŒƒå›´!")
            failed += 1
    
    print(f"\nç»“æœ: {passed} é€šè¿‡, {failed} å¤±è´¥")
    return failed == 0


def test_noise_removal():
    """æµ‹è¯•å™ªå£°è¯ç§»é™¤"""
    
    print("\n" + "=" * 60)
    print("æµ‹è¯•: å™ªå£°åç¼€è¯ç§»é™¤")
    print("=" * 60)
    
    # åŒ…å«å¤§é‡å™ªå£°è¯çš„æ–‡ä»¶å
    noisy_filename = "realvisxl_v3_turbo_fp16_pruned_emaonly_final.safetensors"
    terms = AdvancedTokenizer.extract_search_terms(noisy_filename)
    
    # æ‰€æœ‰æå–çš„è¯ä¸­ä¸åº”åŒ…å«è¿™äº›å™ªå£°è¯
    # NOISE_SUFFIXES ç°åœ¨åœ¨ utils ä¸­
    noise_words = {'fp16', 'pruned', 'emaonly', 'final', 'safetensors'}
    all_terms_text = ' '.join(terms).lower()
    
    found_noise = [w for w in noise_words if w in all_terms_text]
    
    if not found_noise:
        print(f"âœ“ å™ªå£°è¯å·²æ­£ç¡®ç§»é™¤")
        print(f"  è¾“å…¥: {noisy_filename}")
        print(f"  è¾“å‡º: {terms}")
        return True
    else:
        print(f"âœ— ä»åŒ…å«å™ªå£°è¯: {found_noise}")
        print(f"  è¾“å…¥: {noisy_filename}")
        print(f"  è¾“å‡º: {terms}")
        return False


async def test_modelscope_search():
    """æµ‹è¯• ModelScope æœç´¢åŠŸèƒ½ (é›†æˆæµ‹è¯•)"""
    searcher = ModelSearcher()
    
    print("\n" + "=" * 60)
    print("æµ‹è¯•: ModelScope æœç´¢ API")
    print("=" * 60)
    
    test_cases = [
        # (æœç´¢è¯, æœŸæœ›ç»“æœåŒ…å«çš„å…³é”®è¯)
        ("flux", ["flux"]),
        ("qwen", ["qwen"]),
    ]
    
    passed = 0
    failed = 0
    
    for query, expected_keywords in test_cases:
        print(f"\næœç´¢: '{query}'...")
        try:
            # ModelSearcher ç°åœ¨æ˜¯ searcher._search_modelscope_single
            result = await searcher._search_modelscope_single(query, query)
            
            if result:
                name_lower = result.get("name", "").lower()
                page_url = result.get("pageUrl", "")
                score = result.get("score", 0)
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«æœŸæœ›å…³é”®è¯
                has_keyword = any(kw.lower() in name_lower for kw in expected_keywords)
                
                if has_keyword and "modelscope.cn" in page_url:
                    print(f"âœ“ æ‰¾åˆ°æ¨¡å‹: {result.get('name')}")
                    print(f"  -> é¡µé¢: {page_url}")
                    print(f"  -> ç›¸ä¼¼åº¦: {score:.3f}")
                    passed += 1
                else:
                    print(f"âœ— ç»“æœä¸ç¬¦åˆé¢„æœŸ")
                    print(f"  -> ç»“æœ: {result}")
                    failed += 1
            else:
                print(f"âœ— æœªæ‰¾åˆ°ç»“æœ")
                failed += 1
                
        except Exception as e:
            print(f"âœ— æœç´¢å‡ºé”™: {e}")
            failed += 1
    
    print(f"\nç»“æœ: {passed} é€šè¿‡, {failed} å¤±è´¥")
    return failed == 0


if __name__ == "__main__":
    
    print("\nğŸ§ª ComfyUI-LK-Model_Auto-Matching æœç´¢æ¨¡å—æµ‹è¯• (Unit + Integration)\n")
    
    results = []
    results.append(("æœç´¢è¯æå– (Utils)", test_extract_search_terms()))
    results.append(("ç›¸ä¼¼åº¦è®¡ç®— (Utils)", test_calculate_similarity()))
    results.append(("å™ªå£°è¯ç§»é™¤ (Utils)", test_noise_removal()))
    
    # è¿è¡Œ ModelScope å¼‚æ­¥æµ‹è¯•
    print("\n" + "-" * 60)
    print("è¿è¡Œ ModelScope API æµ‹è¯• (éœ€è¦ç½‘ç»œè¿æ¥)...")
    print("-" * 60)
    modelscope_passed = asyncio.run(test_modelscope_search())
    results.append(("ModelScopeæœç´¢", modelscope_passed))
    
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•æ±‡æ€»")
    print("=" * 60)
    
    all_passed = True
    for name, passed in results:
        status = "âœ“ é€šè¿‡" if passed else "âœ— å¤±è´¥"
        print(f"  {status}: {name}")
        if not passed:
            all_passed = False
    
    print("\n" + ("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!" if all_passed else "âš ï¸ å­˜åœ¨å¤±è´¥çš„æµ‹è¯•"))
